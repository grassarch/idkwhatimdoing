{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f373152-0ed1-41a3-a8c1-3e98710e3d19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cython\n",
      "  Downloading Cython-3.0.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Downloading Cython-3.0.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cython\n",
      "Successfully installed cython-3.0.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a989ccb8-acf4-4dfc-9d44-01764b510af8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: git+https://github.com/NVIDIA/NeMo.git@r1.23.0#egg=nemo_toolkit[asr] contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting nemo_toolkit (from nemo_toolkit[asr])\n",
      "  Cloning https://github.com/NVIDIA/NeMo.git (to revision r1.23.0) to /var/tmp/pip-install-g922e0_w/nemo-toolkit_58311ed510fe4e72aacfde1c57ec331b\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/NVIDIA/NeMo.git /var/tmp/pip-install-g922e0_w/nemo-toolkit_58311ed510fe4e72aacfde1c57ec331b\n",
      "  Running command git checkout -b r1.23.0 --track origin/r1.23.0\n",
      "  Switched to a new branch 'r1.23.0'\n",
      "  Branch 'r1.23.0' set up to track remote branch 'r1.23.0' from 'origin'.\n",
      "  Resolved https://github.com/NVIDIA/NeMo.git to commit e772dbf53145a7b45f13440cf6e0ef51035f80dc\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting huggingface-hub (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numba in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nemo_toolkit->nemo_toolkit[asr]) (0.59.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nemo_toolkit->nemo_toolkit[asr]) (1.26.4)\n",
      "Collecting onnx>=1.7.0 (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nemo_toolkit->nemo_toolkit[asr]) (2.9.0)\n",
      "Requirement already satisfied: ruamel.yaml in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nemo_toolkit->nemo_toolkit[asr]) (0.18.6)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nemo_toolkit->nemo_toolkit[asr]) (1.4.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nemo_toolkit->nemo_toolkit[asr]) (69.5.1)\n",
      "Collecting tensorboard (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting text-unidecode (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nemo_toolkit->nemo_toolkit[asr]) (1.13.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nemo_toolkit->nemo_toolkit[asr]) (4.66.2)\n",
      "Collecting triton (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting wget (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: wrapt in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nemo_toolkit->nemo_toolkit[asr]) (1.16.0)\n",
      "Collecting braceexpand (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting editdistance (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting g2p-en (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nemo_toolkit->nemo_toolkit[asr]) (8.1.2)\n",
      "Collecting jiwer (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached jiwer-3.0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting kaldi-python-io (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached kaldi-python-io-1.2.2.tar.gz (8.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting kaldiio (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached kaldiio-2.18.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting lhotse>=1.20.0 (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached lhotse-1.23.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting librosa>=0.10.0 (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached librosa-0.10.2-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting marshmallow (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nemo_toolkit->nemo_toolkit[asr]) (3.8.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nemo_toolkit->nemo_toolkit[asr]) (24.0)\n",
      "Collecting pyannote.core (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyannote.metrics (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pydub (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyloudnorm (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting resampy (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nemo_toolkit->nemo_toolkit[asr]) (1.11.4)\n",
      "Collecting soundfile (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\n",
      "Collecting sox (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached sox-1.5.0.tar.gz (63 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting texterrors (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached texterrors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting hydra-core<=1.3.2,>1.3 (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting omegaconf<=2.3 (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytorch-lightning<=2.0.7,>=2.0 (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached pytorch_lightning-2.0.7-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting torchmetrics>=0.11.0 (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached torchmetrics-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting transformers>=4.36.0 (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
      "Collecting wandb (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting webdataset<=0.1.62,>=0.1.48 (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached webdataset-0.1.62-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting datasets (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting inflect (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached inflect-7.2.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nemo_toolkit->nemo_toolkit[asr]) (2.2.2)\n",
      "Collecting sacremoses>=0.0.43 (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting sentencepiece<1.0.0 (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting youtokentome>=1.0.5 (from nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached youtokentome-1.0.6.tar.gz (86 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core<=1.3.2,>1.3->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting audioread>=2.1.9 (from lhotse>=1.20.0->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: click>=7.1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from lhotse>=1.20.0->nemo_toolkit->nemo_toolkit[asr]) (8.1.7)\n",
      "Collecting cytoolz>=0.10.1 (from lhotse>=1.20.0->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading cytoolz-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting intervaltree>=3.1.0 (from lhotse>=1.20.0->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.3.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from lhotse>=1.20.0->nemo_toolkit->nemo_toolkit[asr]) (6.0.1)\n",
      "Requirement already satisfied: tabulate>=0.8.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from lhotse>=1.20.0->nemo_toolkit->nemo_toolkit[asr]) (0.9.0)\n",
      "Collecting lilcom>=1.1.0 (from lhotse>=1.20.0->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading lilcom-1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from librosa>=0.10.0->nemo_toolkit->nemo_toolkit[asr]) (1.4.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from librosa>=0.10.0->nemo_toolkit->nemo_toolkit[asr]) (5.1.1)\n",
      "Collecting pooch>=1.1 (from librosa>=0.10.0->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached pooch-1.8.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa>=0.10.0->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached soxr-0.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from librosa>=0.10.0->nemo_toolkit->nemo_toolkit[asr]) (4.11.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from librosa>=0.10.0->nemo_toolkit->nemo_toolkit[asr]) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from librosa>=0.10.0->nemo_toolkit->nemo_toolkit[asr]) (1.0.8)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from numba->nemo_toolkit->nemo_toolkit[asr]) (0.42.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from onnx>=1.7.0->nemo_toolkit->nemo_toolkit[asr]) (3.20.3)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning<=2.0.7,>=2.0->nemo_toolkit->nemo_toolkit[asr]) (2024.3.1)\n",
      "Collecting lightning-utilities>=0.7.0 (from pytorch-lightning<=2.0.7,>=2.0->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting regex (from sacremoses>=0.0.43->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached regex-2024.5.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from scikit-learn->nemo_toolkit->nemo_toolkit[asr]) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from soundfile->nemo_toolkit->nemo_toolkit[asr]) (1.16.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->nemo_toolkit->nemo_toolkit[asr]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->nemo_toolkit->nemo_toolkit[asr]) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->nemo_toolkit->nemo_toolkit[asr]) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch->nemo_toolkit->nemo_toolkit[asr]) (11.7.99)\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->nemo_toolkit->nemo_toolkit[asr]) (0.43.0)\n",
      "Collecting pretty-errors==1.2.25 (from torchmetrics>=0.11.0->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading pretty_errors-1.2.25-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pretty-errors==1.2.25->torchmetrics>=0.11.0->nemo_toolkit->nemo_toolkit[asr]) (0.4.6)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers>=4.36.0->nemo_toolkit->nemo_toolkit[asr]) (3.14.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers>=4.36.0->nemo_toolkit->nemo_toolkit[asr]) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers>=4.36.0->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.36.0->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets->nemo_toolkit->nemo_toolkit[asr]) (16.0.0)\n",
      "Collecting pyarrow-hotfix (from datasets->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datasets->nemo_toolkit->nemo_toolkit[asr]) (3.9.5)\n",
      "Collecting nltk>=3.2.4 (from g2p-en->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting distance>=0.1.3 (from g2p-en->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: more-itertools in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from inflect->nemo_toolkit->nemo_toolkit[asr]) (10.2.0)\n",
      "Requirement already satisfied: typeguard>=4.0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from inflect->nemo_toolkit->nemo_toolkit[asr]) (4.2.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (8.21.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (3.0.10)\n",
      "Collecting rapidfuzz<4,>=3 (from jiwer->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Using cached rapidfuzz-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib->nemo_toolkit->nemo_toolkit[asr]) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib->nemo_toolkit->nemo_toolkit[asr]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib->nemo_toolkit->nemo_toolkit[asr]) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib->nemo_toolkit->nemo_toolkit[asr]) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib->nemo_toolkit->nemo_toolkit[asr]) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib->nemo_toolkit->nemo_toolkit[asr]) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from python-dateutil->nemo_toolkit->nemo_toolkit[asr]) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->nemo_toolkit->nemo_toolkit[asr]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->nemo_toolkit->nemo_toolkit[asr]) (2024.1)\n",
      "Collecting sortedcontainers>=2.0.4 (from pyannote.core->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pyannote.database>=4.0.1 (from pyannote.metrics->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading pyannote.database-5.1.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting docopt>=0.6.2 (from pyannote.metrics->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sympy>=1.1 (from pyannote.metrics->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting future>=0.16.0 (from pyloudnorm->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ruamel.yaml->nemo_toolkit->nemo_toolkit[asr]) (0.2.8)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from tensorboard->nemo_toolkit->nemo_toolkit[asr]) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from tensorboard->nemo_toolkit->nemo_toolkit[asr]) (1.63.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting pybind11 (from texterrors->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading pybind11-2.12.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting plac (from texterrors->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading plac-1.4.3-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting loguru (from texterrors->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting termcolor (from texterrors->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting Levenshtein (from texterrors->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from wandb->nemo_toolkit->nemo_toolkit[asr]) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from wandb->nemo_toolkit->nemo_toolkit[asr]) (4.2.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from wandb->nemo_toolkit->nemo_toolkit[asr]) (5.9.3)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading sentry_sdk-2.1.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cffi>=1.0->soundfile->nemo_toolkit->nemo_toolkit[asr]) (2.22)\n",
      "Collecting toolz>=0.8.0 (from cytoolz>=0.10.1->lhotse>=1.20.0->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets->nemo_toolkit->nemo_toolkit[asr]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets->nemo_toolkit->nemo_toolkit[asr]) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets->nemo_toolkit->nemo_toolkit[asr]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets->nemo_toolkit->nemo_toolkit[asr]) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets->nemo_toolkit->nemo_toolkit[asr]) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->datasets->nemo_toolkit->nemo_toolkit[asr]) (4.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit->nemo_toolkit[asr]) (4.0.11)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (4.9.0)\n",
      "Requirement already satisfied: typer>=0.12.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit->nemo_toolkit[asr]) (0.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers>=4.36.0->nemo_toolkit->nemo_toolkit[asr]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers>=4.36.0->nemo_toolkit->nemo_toolkit[asr]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers>=4.36.0->nemo_toolkit->nemo_toolkit[asr]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers>=4.36.0->nemo_toolkit->nemo_toolkit[asr]) (2024.2.2)\n",
      "Collecting mpmath>=0.19 (from sympy>=1.1->pyannote.metrics->nemo_toolkit->nemo_toolkit[asr])\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->nemo_toolkit->nemo_toolkit[asr]) (2.1.5)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit->nemo_toolkit[asr]) (5.0.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (0.2.13)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit->nemo_toolkit[asr]) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit->nemo_toolkit[asr]) (13.7.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->nemo_toolkit->nemo_toolkit[asr]) (0.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit->nemo_toolkit[asr]) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit->nemo_toolkit[asr]) (0.1.2)\n",
      "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lhotse-1.23.0-py3-none-any.whl (772 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.4/772.4 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached librosa-0.10.2-py3-none-any.whl (260 kB)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_lightning-2.0.7-py3-none-any.whl (724 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.0/725.0 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
      "Downloading torchmetrics-1.4.0-py3-none-any.whl (868 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pretty_errors-1.2.25-py3-none-any.whl (17 kB)\n",
      "Downloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading webdataset-0.1.62-py3-none-any.whl (32 kB)\n",
      "Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.8/401.8 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading inflect-7.2.1-py3-none-any.whl (34 kB)\n",
      "Using cached jiwer-3.0.4-py3-none-any.whl (21 kB)\n",
      "Downloading kaldiio-2.18.0-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
      "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading texterrors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading cytoolz-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Downloading lilcom-1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached pooch-1.8.1-py3-none-any.whl (62 kB)\n",
      "Downloading pyannote.database-5.1.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached rapidfuzz-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "Using cached regex-2024.5.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (774 kB)\n",
      "Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.1.1-py2.py3-none-any.whl (277 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.3/277.3 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached soxr-0.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading plac-1.4.3-py2.py3-none-any.whl (22 kB)\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading pybind11-2.12.0-py3-none-any.whl (234 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.0/235.0 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: nemo_toolkit, antlr4-python3-runtime, youtokentome, kaldi-python-io, sox, wget, distance, docopt, intervaltree\n",
      "  Building wheel for nemo_toolkit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nemo_toolkit: filename=nemo_toolkit-1.23.0-py3-none-any.whl size=3157314 sha256=46e99df0ede24c312702c84c36969231cdc657c6ab7158a1556997ae721cf6b8\n",
      "  Stored in directory: /var/tmp/pip-ephem-wheel-cache-vw9fqoww/wheels/7b/32/f9/74b7daae7613ff29552feeac6f0ba8ee79304f00ca568f9546\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=59c3fdbedb20e85fda396bfc8a301686aaf19da2eaf45f67e958f82220c05414\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "  Building wheel for youtokentome (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for youtokentome: filename=youtokentome-1.0.6-cp310-cp310-linux_x86_64.whl size=189549 sha256=bf52ec528b1bb864a7d17df55e0a614f73f12bc879b845f9380a3ca4b06d5692\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/df/85/f8/301d2ba45f43f30bed2fe413efa760bc726b8b660ed9c2900c\n",
      "  Building wheel for kaldi-python-io (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaldi-python-io: filename=kaldi_python_io-1.2.2-py3-none-any.whl size=8949 sha256=1a1c4c1239ad0a371b8f6dbc4d295895e8df50d2adf3f84f8f966d5184b06eaa\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/b7/23/5f/49d3a826be576faf61d84e8028e1914bb36a5586ee2613b087\n",
      "  Building wheel for sox (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sox: filename=sox-1.5.0-py3-none-any.whl size=40038 sha256=91f154be71363158626557618d48102c318bd4297dac71e106ad51be706e1ce2\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/74/e7/7b/8033be3ec5e4994595d01269fc9657c8fd83a0dcbf8536666a\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=98070ee4a5877fd7eedb015325e5d24feb36cb28822f495ae65a649371b71269\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
      "  Building wheel for distance (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16258 sha256=750e0f178baba614c074265acfb7efdc59942a9d24dd34607ea47d29ef080384\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=aed17d9a691b4aa512523debf1fa35eec409ef6f2c5236259c8de15fde087950\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "  Building wheel for intervaltree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26096 sha256=72a4ce5f4c9d7d743909f9122ab65bdab1495f965df4a1e21ee3ff63f59183fe\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
      "Successfully built nemo_toolkit antlr4-python3-runtime youtokentome kaldi-python-io sox wget distance docopt intervaltree\n",
      "Installing collected packages: wget, text-unidecode, sortedcontainers, sentencepiece, pydub, plac, mpmath, docopt, distance, braceexpand, antlr4-python3-runtime, youtokentome, xxhash, werkzeug, webdataset, triton, toolz, termcolor, tensorboard-data-server, sympy, soxr, sox, setproctitle, sentry-sdk, safetensors, regex, rapidfuzz, pybind11, pyarrow-hotfix, pretty-errors, onnx, omegaconf, marshmallow, markdown, loguru, lilcom, lightning-utilities, kaldiio, kaldi-python-io, intervaltree, future, editdistance, docker-pycreds, dill, audioread, tensorboard, soundfile, sacremoses, resampy, pyloudnorm, pyannote.core, pooch, nltk, multiprocess, Levenshtein, jiwer, inflect, hydra-core, huggingface-hub, cytoolz, wandb, tokenizers, texterrors, librosa, lhotse, g2p-en, transformers, torchmetrics, pyannote.database, nemo_toolkit, datasets, pytorch-lightning, pyannote.metrics\n",
      "Successfully installed Levenshtein-0.25.1 antlr4-python3-runtime-4.9.3 audioread-3.0.1 braceexpand-0.1.7 cytoolz-0.12.3 datasets-2.19.1 dill-0.3.8 distance-0.1.3 docker-pycreds-0.4.0 docopt-0.6.2 editdistance-0.8.1 future-1.0.0 g2p-en-2.1.0 huggingface-hub-0.23.0 hydra-core-1.3.2 inflect-7.2.1 intervaltree-3.1.0 jiwer-3.0.4 kaldi-python-io-1.2.2 kaldiio-2.18.0 lhotse-1.23.0 librosa-0.10.2 lightning-utilities-0.11.2 lilcom-1.7 loguru-0.7.2 markdown-3.6 marshmallow-3.21.2 mpmath-1.3.0 multiprocess-0.70.16 nemo_toolkit-1.23.0 nltk-3.8.1 omegaconf-2.3.0 onnx-1.16.0 plac-1.4.3 pooch-1.8.1 pretty-errors-1.2.25 pyannote.core-5.0.0 pyannote.database-5.1.0 pyannote.metrics-3.2.1 pyarrow-hotfix-0.6 pybind11-2.12.0 pydub-0.25.1 pyloudnorm-0.1.1 pytorch-lightning-2.0.7 rapidfuzz-3.9.0 regex-2024.5.10 resampy-0.4.3 sacremoses-0.1.1 safetensors-0.4.3 sentencepiece-0.2.0 sentry-sdk-2.1.1 setproctitle-1.3.3 sortedcontainers-2.4.0 soundfile-0.12.1 sox-1.5.0 soxr-0.3.7 sympy-1.12 tensorboard-2.16.2 tensorboard-data-server-0.7.2 termcolor-2.4.0 text-unidecode-1.3 texterrors-0.4.4 tokenizers-0.19.1 toolz-0.12.1 torchmetrics-1.4.0 transformers-4.40.2 triton-2.3.0 wandb-0.17.0 webdataset-0.1.62 werkzeug-3.0.3 wget-3.2 xxhash-3.4.1 youtokentome-1.0.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/NVIDIA/NeMo.git@r1.23.0#egg=nemo_toolkit[asr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "602d1272-4952-4efb-b825-7858b9a7a7c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-12 05:30:33 nemo_logging:349] /opt/conda/envs/pytorch/lib/python3.10/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6467fe8a4ea848b2b3e9415a6cbf160e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "canary-1b.nemo:   0%|          | 0.00/4.07G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-12 05:34:26 mixins:196] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2024-05-12 05:34:26 mixins:330] Tokenizer SentencePieceTokenizer initialized with 32 tokens\n",
      "[NeMo I 2024-05-12 05:34:26 mixins:330] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2024-05-12 05:34:26 mixins:330] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2024-05-12 05:34:26 mixins:330] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2024-05-12 05:34:26 mixins:330] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2024-05-12 05:34:26 aggregate_tokenizer:72] Aggregate vocab size: 4128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-12 05:34:27 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    tarred_audio_filepaths: null\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    shuffle: true\n",
      "    batch_size: null\n",
      "    num_workers: 8\n",
      "    use_lhotse: true\n",
      "    max_duration: 40\n",
      "    pin_memory: true\n",
      "    use_bucketing: false\n",
      "    bucket_duration_bins: null\n",
      "    num_buckets: 1\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    batch_duration: 360\n",
      "    quadratic_duration: 15\n",
      "    bucket_buffer_size: 20000\n",
      "    shuffle_buffer_size: 10000\n",
      "    \n",
      "[NeMo W 2024-05-12 05:34:27 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: false\n",
      "    num_workers: 0\n",
      "    pin_memory: true\n",
      "    tarred_audio_filepaths: null\n",
      "    use_lhotse: true\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    use_bucketing: false\n",
      "    \n",
      "[NeMo W 2024-05-12 05:34:27 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 0\n",
      "    pin_memory: true\n",
      "    tarred_audio_filepaths: null\n",
      "    use_lhotse: true\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    use_bucketing: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-12 05:34:27 features:289] PADDING: 0\n",
      "[NeMo I 2024-05-12 05:35:09 save_restore_connector:249] Model EncDecMultiTaskModel was successfully restored from /home/jupyter/.cache/huggingface/hub/models--nvidia--canary-1b/snapshots/dd32c0c709e2bfc79f583e16b9df4b3a160f7e86/canary-1b.nemo.\n",
      "[NeMo I 2024-05-12 05:35:09 aed_multitask_models:214] Changed decoding strategy to \n",
      "    strategy: beam\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: null\n",
      "    compute_langs: false\n",
      "    beam:\n",
      "      beam_size: 1\n",
      "      search_type: default\n",
      "      len_pen: 1.0\n",
      "      max_generation_delta: 20\n",
      "      return_best_hypothesis: true\n",
      "      preserve_alignments: false\n",
      "    temperature: 1.0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from nemo.collections.asr.models import EncDecMultiTaskModel\n",
    "\n",
    "# load model\n",
    "canary_model = EncDecMultiTaskModel.from_pretrained('nvidia/canary-1b')\n",
    "\n",
    "# update dcode params\n",
    "decode_cfg = canary_model.cfg.decoding\n",
    "decode_cfg.beam.beam_size = 1\n",
    "canary_model.change_decoding_strategy(decode_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fc3ddd4-152c-44e2-b037-7e938c29132b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Can't find /home/jupyter/.cache/huggingface/hub/models--nvidia--canary-1b/snapshots/dd32c0c709e2bfc79f583e16b9df4b3a160f7e86/canary-1b.nemo",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnemo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masr\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnemo_asr\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# load model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m canary_model \u001b[38;5;241m=\u001b[39m \u001b[43mnemo_asr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEncDecMultiTaskModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestore_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/jupyter/.cache/huggingface/hub/models--nvidia--canary-1b/snapshots/dd32c0c709e2bfc79f583e16b9df4b3a160f7e86/canary-1b.nemo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# update dcode params\u001b[39;00m\n\u001b[1;32m      5\u001b[0m decode_cfg \u001b[38;5;241m=\u001b[39m canary_model\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdecoding\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/nemo/core/classes/modelPT.py:443\u001b[0m, in \u001b[0;36mModelPT.restore_from\u001b[0;34m(cls, restore_path, override_config_path, map_location, strict, return_config, save_restore_connector, trainer)\u001b[0m\n\u001b[1;32m    440\u001b[0m     restore_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(save_restore_connector\u001b[38;5;241m.\u001b[39mmodel_extracted_dir))\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(restore_path):\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrestore_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    445\u001b[0m app_state \u001b[38;5;241m=\u001b[39m AppState()\n\u001b[1;32m    446\u001b[0m app_state\u001b[38;5;241m.\u001b[39mmodel_restore_path \u001b[38;5;241m=\u001b[39m restore_path\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Can't find /home/jupyter/.cache/huggingface/hub/models--nvidia--canary-1b/snapshots/dd32c0c709e2bfc79f583e16b9df4b3a160f7e86/canary-1b.nemo"
     ]
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "# load model\n",
    "canary_model = nemo_asr.models.EncDecMultiTaskModel.restore_from(restore_path='/home/jupyter/.cache/huggingface/hub/models--nvidia--canary-1b/snapshots/dd32c0c709e2bfc79f583e16b9df4b3a160f7e86/canary-1b.nemo')\n",
    "# update dcode params\n",
    "decode_cfg = canary_model.cfg.decoding\n",
    "decode_cfg.beam.beam_size = 1\n",
    "canary_model.change_decoding_strategy(decode_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e18c772-7602-4cc2-b637-662b7a44254b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13b5128f83241198cc0d293f7c1225c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Heading his one five zero target is green commercial aircraft tool to deploy his electromagnetic pulse.']\n"
     ]
    }
   ],
   "source": [
    "predicted_text = canary_model.transcribe(\n",
    "    paths2audio_files=[\"./novice/audio/audio_0.wav\"],\n",
    "    batch_size=16,  # batch size to run the inference with\n",
    ")\n",
    "print(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f4c5346-3fd8-4f91-9855-257496e66d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nemo_toolkit[all] in /opt/conda/lib/python3.10/site-packages (1.23.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.23.0)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.59.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.26.4)\n",
      "Requirement already satisfied: onnx>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.9.0)\n",
      "Requirement already satisfied: ruamel.yaml in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.18.6)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.4.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (69.5.1)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.16.2)\n",
      "Requirement already satisfied: text-unidecode in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.13.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (4.66.2)\n",
      "Requirement already satisfied: triton in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.3.0)\n",
      "Requirement already satisfied: wget in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (3.2)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.16.0)\n",
      "Requirement already satisfied: black==19.10b0 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (19.10b0)\n",
      "Collecting click==8.0.2 (from nemo_toolkit[all])\n",
      "  Using cached click-8.0.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: isort<6.0.0,>5.1.0 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (5.13.2)\n",
      "Requirement already satisfied: parameterized in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.9.0)\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (8.2.0)\n",
      "Requirement already satisfied: pytest-runner in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (6.0.1)\n",
      "Requirement already satisfied: sphinx in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (7.3.7)\n",
      "Requirement already satisfied: sphinxcontrib-bibtex in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.6.2)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.17.0)\n",
      "Requirement already satisfied: hydra-core<=1.3.2,>1.3 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.3.2)\n",
      "Requirement already satisfied: omegaconf<=2.3 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.3.0)\n",
      "Requirement already satisfied: pytorch-lightning<=2.0.7,>=2.0 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.0.7)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.4.0)\n",
      "Requirement already satisfied: transformers>=4.36.0 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (4.40.2)\n",
      "Requirement already satisfied: webdataset<=0.1.62,>=0.1.48 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.1.62)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.19.1)\n",
      "Requirement already satisfied: inflect in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (7.2.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.2.2)\n",
      "Requirement already satisfied: sacremoses>=0.0.43 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.1.1)\n",
      "Requirement already satisfied: sentencepiece<1.0.0 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.2.0)\n",
      "Requirement already satisfied: youtokentome>=1.0.5 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.0.6)\n",
      "Requirement already satisfied: braceexpand in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.1.7)\n",
      "Requirement already satisfied: editdistance in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.8.1)\n",
      "Requirement already satisfied: g2p-en in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.1.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (8.1.2)\n",
      "Requirement already satisfied: jiwer in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (3.0.4)\n",
      "Requirement already satisfied: kaldi-python-io in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.2.2)\n",
      "Requirement already satisfied: kaldiio in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.18.0)\n",
      "Requirement already satisfied: lhotse>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.23.0)\n",
      "Requirement already satisfied: librosa>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.10.2)\n",
      "Requirement already satisfied: marshmallow in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (3.21.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (3.8.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (24.0)\n",
      "Requirement already satisfied: pyannote.core in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (5.0.0)\n",
      "Requirement already satisfied: pyannote.metrics in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (3.2.1)\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.25.1)\n",
      "Requirement already satisfied: pyloudnorm in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.1.1)\n",
      "Requirement already satisfied: resampy in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.4.3)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.11.4)\n",
      "Requirement already satisfied: soundfile in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.12.1)\n",
      "Requirement already satisfied: sox in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.5.0)\n",
      "Requirement already satisfied: texterrors in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.4.4)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.34.103)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.8.0)\n",
      "Requirement already satisfied: faiss-cpu in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.8.0)\n",
      "Requirement already satisfied: fasttext in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.9.2)\n",
      "Requirement already satisfied: flask-restful in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.3.10)\n",
      "Requirement already satisfied: ftfy in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (6.2.0)\n",
      "Requirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (5.2.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (3.11.0)\n",
      "Requirement already satisfied: ijson in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (3.2.3)\n",
      "Requirement already satisfied: jieba in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.42.1)\n",
      "Requirement already satisfied: markdown2 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.4.13)\n",
      "Requirement already satisfied: megatron-core==0.5.0 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.5.0)\n",
      "Requirement already satisfied: nltk>=3.6.5 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (3.8.1)\n",
      "Requirement already satisfied: opencc<1.1.7 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.1.6)\n",
      "Requirement already satisfied: pangu in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (4.0.6.1)\n",
      "Requirement already satisfied: rapidfuzz in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (3.9.0)\n",
      "Requirement already satisfied: rouge-score in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.1.2)\n",
      "Requirement already satisfied: sacrebleu in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.4.2)\n",
      "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.7.0)\n",
      "Requirement already satisfied: tensorstore<0.1.46 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.1.45)\n",
      "Requirement already satisfied: zarr in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.18.0)\n",
      "Requirement already satisfied: attrdict in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.0.1)\n",
      "Requirement already satisfied: kornia in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.7.2)\n",
      "Requirement already satisfied: pypinyin in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.51.0)\n",
      "Requirement already satisfied: pypinyin-dict in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.8.0)\n",
      "Requirement already satisfied: progress>=1.5 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.6)\n",
      "Requirement already satisfied: tabulate>=0.8.7 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.9.0)\n",
      "Requirement already satisfied: textdistance>=4.1.5 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (4.6.2)\n",
      "Requirement already satisfied: addict in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.4.0)\n",
      "Requirement already satisfied: clip in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.2.0)\n",
      "Requirement already satisfied: diffusers>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.27.2)\n",
      "Requirement already satisfied: einops-exts in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.0.4)\n",
      "Requirement already satisfied: imageio in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.34.1)\n",
      "Requirement already satisfied: nerfacc>=0.5.3 in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.5.3)\n",
      "Requirement already satisfied: open-clip-torch in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (2.24.0)\n",
      "Requirement already satisfied: PyMCubes in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.1.4)\n",
      "Requirement already satisfied: taming-transformers in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.0.1)\n",
      "Requirement already satisfied: torchdiffeq in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.2.3)\n",
      "Requirement already satisfied: torchsde in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (0.2.6)\n",
      "Requirement already satisfied: trimesh in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (4.3.2)\n",
      "Requirement already satisfied: nemo-text-processing in /opt/conda/lib/python3.10/site-packages (from nemo_toolkit[all]) (1.0.2)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /opt/conda/lib/python3.10/site-packages (from black==19.10b0->nemo_toolkit[all]) (23.2.0)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.10/site-packages (from black==19.10b0->nemo_toolkit[all]) (1.4.4)\n",
      "Requirement already satisfied: toml>=0.9.4 in /opt/conda/lib/python3.10/site-packages (from black==19.10b0->nemo_toolkit[all]) (0.10.2)\n",
      "Requirement already satisfied: typed-ast>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from black==19.10b0->nemo_toolkit[all]) (1.5.5)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from black==19.10b0->nemo_toolkit[all]) (2024.5.10)\n",
      "Requirement already satisfied: pathspec<1,>=0.6 in /opt/conda/lib/python3.10/site-packages (from black==19.10b0->nemo_toolkit[all]) (0.12.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers>=0.19.3->nemo_toolkit[all]) (7.0.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers>=0.19.3->nemo_toolkit[all]) (3.14.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers>=0.19.3->nemo_toolkit[all]) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from diffusers>=0.19.3->nemo_toolkit[all]) (0.4.3)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers>=0.19.3->nemo_toolkit[all]) (10.3.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->nemo_toolkit[all]) (2024.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->nemo_toolkit[all]) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->nemo_toolkit[all]) (4.11.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.10/site-packages (from hydra-core<=1.3.2,>1.3->nemo_toolkit[all]) (4.9.3)\n",
      "INFO: pip is looking at multiple versions of jiwer to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jiwer (from nemo_toolkit[all])\n",
      "  Using cached jiwer-3.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached jiwer-3.0.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached jiwer-3.0.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached jiwer-3.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached jiwer-2.6.0-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached jiwer-2.5.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting rapidfuzz (from nemo_toolkit[all])\n",
      "  Using cached rapidfuzz-2.13.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from lhotse>=1.20.0->nemo_toolkit[all]) (3.0.1)\n",
      "Requirement already satisfied: cytoolz>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from lhotse>=1.20.0->nemo_toolkit[all]) (0.12.3)\n",
      "Requirement already satisfied: intervaltree>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from lhotse>=1.20.0->nemo_toolkit[all]) (3.1.0)\n",
      "Requirement already satisfied: lilcom>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from lhotse>=1.20.0->nemo_toolkit[all]) (1.7)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->nemo_toolkit[all]) (1.4.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->nemo_toolkit[all]) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->nemo_toolkit[all]) (1.8.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->nemo_toolkit[all]) (0.3.7)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->nemo_toolkit[all]) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa>=0.10.0->nemo_toolkit[all]) (1.0.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->nemo_toolkit[all]) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->nemo_toolkit[all]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->nemo_toolkit[all]) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->nemo_toolkit[all]) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->nemo_toolkit[all]) (3.1.2)\n",
      "Requirement already satisfied: rich>=12 in /opt/conda/lib/python3.10/site-packages (from nerfacc>=0.5.3->nemo_toolkit[all]) (13.7.1)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->nemo_toolkit[all]) (0.42.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx>=1.7.0->nemo_toolkit[all]) (3.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil->nemo_toolkit[all]) (1.16.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning<=2.0.7,>=2.0->nemo_toolkit[all]) (0.11.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->nemo_toolkit[all]) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile->nemo_toolkit[all]) (1.16.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch->nemo_toolkit[all]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch->nemo_toolkit[all]) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch->nemo_toolkit[all]) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch->nemo_toolkit[all]) (11.7.99)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->nemo_toolkit[all]) (0.43.0)\n",
      "Requirement already satisfied: pretty-errors==1.2.25 in /opt/conda/lib/python3.10/site-packages (from torchmetrics>=0.11.0->nemo_toolkit[all]) (1.2.25)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from pretty-errors==1.2.25->torchmetrics>=0.11.0->nemo_toolkit[all]) (0.4.6)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.36.0->nemo_toolkit[all]) (0.19.1)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.103 in /opt/conda/lib/python3.10/site-packages (from boto3->nemo_toolkit[all]) (1.34.103)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->nemo_toolkit[all]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3->nemo_toolkit[all]) (0.10.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->nemo_toolkit[all]) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->nemo_toolkit[all]) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->nemo_toolkit[all]) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->nemo_toolkit[all]) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->nemo_toolkit[all]) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->nemo_toolkit[all]) (3.9.5)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.10/site-packages (from fasttext->nemo_toolkit[all]) (2.12.0)\n",
      "Requirement already satisfied: aniso8601>=0.82 in /opt/conda/lib/python3.10/site-packages (from flask-restful->nemo_toolkit[all]) (9.0.1)\n",
      "Requirement already satisfied: Flask>=0.8 in /opt/conda/lib/python3.10/site-packages (from flask-restful->nemo_toolkit[all]) (2.2.5)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from flask-restful->nemo_toolkit[all]) (2024.1)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->nemo_toolkit[all]) (0.2.13)\n",
      "Requirement already satisfied: distance>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from g2p-en->nemo_toolkit[all]) (0.1.3)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from inflect->nemo_toolkit[all]) (10.2.0)\n",
      "Requirement already satisfied: typeguard>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from inflect->nemo_toolkit[all]) (4.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown->nemo_toolkit[all]) (4.12.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->nemo_toolkit[all]) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->nemo_toolkit[all]) (8.21.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->nemo_toolkit[all]) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->nemo_toolkit[all]) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->nemo_toolkit[all]) (3.0.10)\n",
      "Requirement already satisfied: kornia-rs>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from kornia->nemo_toolkit[all]) (0.1.3)\n",
      "Requirement already satisfied: cdifflib in /opt/conda/lib/python3.10/site-packages (from nemo-text-processing->nemo_toolkit[all]) (1.2.6)\n",
      "Requirement already satisfied: pynini==2.1.5 in /opt/conda/lib/python3.10/site-packages (from nemo-text-processing->nemo_toolkit[all]) (2.1.5)\n",
      "Requirement already satisfied: Cython>=0.29 in /opt/conda/lib/python3.10/site-packages (from pynini==2.1.5->nemo-text-processing->nemo_toolkit[all]) (3.0.10)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from open-clip-torch->nemo_toolkit[all]) (0.14.0)\n",
      "Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from open-clip-torch->nemo_toolkit[all]) (0.9.16)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->nemo_toolkit[all]) (2024.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from pyannote.core->nemo_toolkit[all]) (2.4.0)\n",
      "Requirement already satisfied: pyannote.database>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from pyannote.metrics->nemo_toolkit[all]) (5.1.0)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /opt/conda/lib/python3.10/site-packages (from pyannote.metrics->nemo_toolkit[all]) (0.6.2)\n",
      "Requirement already satisfied: sympy>=1.1 in /opt/conda/lib/python3.10/site-packages (from pyannote.metrics->nemo_toolkit[all]) (1.12)\n",
      "Requirement already satisfied: future>=0.16.0 in /opt/conda/lib/python3.10/site-packages (from pyloudnorm->nemo_toolkit[all]) (1.0.0)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->nemo_toolkit[all]) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=1.5 in /opt/conda/lib/python3.10/site-packages (from pytest->nemo_toolkit[all]) (1.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->nemo_toolkit[all]) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->nemo_toolkit[all]) (2.0.1)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score->nemo_toolkit[all]) (2.1.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from ruamel.yaml->nemo_toolkit[all]) (0.2.8)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu->nemo_toolkit[all]) (2.8.2)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu->nemo_toolkit[all]) (5.2.1)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /opt/conda/lib/python3.10/site-packages (from sphinx->nemo_toolkit[all]) (1.0.8)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /opt/conda/lib/python3.10/site-packages (from sphinx->nemo_toolkit[all]) (1.0.6)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /opt/conda/lib/python3.10/site-packages (from sphinx->nemo_toolkit[all]) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from sphinx->nemo_toolkit[all]) (2.0.5)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /opt/conda/lib/python3.10/site-packages (from sphinx->nemo_toolkit[all]) (1.1.10)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /opt/conda/lib/python3.10/site-packages (from sphinx->nemo_toolkit[all]) (1.0.7)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.10/site-packages (from sphinx->nemo_toolkit[all]) (3.1.3)\n",
      "Requirement already satisfied: Pygments>=2.14 in /opt/conda/lib/python3.10/site-packages (from sphinx->nemo_toolkit[all]) (2.17.2)\n",
      "Requirement already satisfied: docutils<0.22,>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from sphinx->nemo_toolkit[all]) (0.21.2)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in /opt/conda/lib/python3.10/site-packages (from sphinx->nemo_toolkit[all]) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in /opt/conda/lib/python3.10/site-packages (from sphinx->nemo_toolkit[all]) (2.14.0)\n",
      "Requirement already satisfied: alabaster~=0.7.14 in /opt/conda/lib/python3.10/site-packages (from sphinx->nemo_toolkit[all]) (0.7.16)\n",
      "Requirement already satisfied: imagesize>=1.3 in /opt/conda/lib/python3.10/site-packages (from sphinx->nemo_toolkit[all]) (1.4.1)\n",
      "Requirement already satisfied: pybtex>=0.24 in /opt/conda/lib/python3.10/site-packages (from sphinxcontrib-bibtex->nemo_toolkit[all]) (0.24.0)\n",
      "Requirement already satisfied: pybtex-docutils>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from sphinxcontrib-bibtex->nemo_toolkit[all]) (1.0.3)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->nemo_toolkit[all]) (1.63.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->nemo_toolkit[all]) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->nemo_toolkit[all]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->nemo_toolkit[all]) (3.0.3)\n",
      "Requirement already satisfied: plac in /opt/conda/lib/python3.10/site-packages (from texterrors->nemo_toolkit[all]) (1.4.3)\n",
      "Requirement already satisfied: loguru in /opt/conda/lib/python3.10/site-packages (from texterrors->nemo_toolkit[all]) (0.7.2)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from texterrors->nemo_toolkit[all]) (2.4.0)\n",
      "Requirement already satisfied: Levenshtein in /opt/conda/lib/python3.10/site-packages (from texterrors->nemo_toolkit[all]) (0.22.0)\n",
      "Requirement already satisfied: trampoline>=0.1.2 in /opt/conda/lib/python3.10/site-packages (from torchsde->nemo_toolkit[all]) (0.1.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb->nemo_toolkit[all]) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->nemo_toolkit[all]) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb->nemo_toolkit[all]) (4.2.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->nemo_toolkit[all]) (5.9.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->nemo_toolkit[all]) (2.1.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb->nemo_toolkit[all]) (1.3.3)\n",
      "Requirement already satisfied: asciitree in /opt/conda/lib/python3.10/site-packages (from zarr->nemo_toolkit[all]) (0.3.3)\n",
      "Requirement already satisfied: numcodecs>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from zarr->nemo_toolkit[all]) (0.12.1)\n",
      "Requirement already satisfied: fasteners in /opt/conda/lib/python3.10/site-packages (from zarr->nemo_toolkit[all]) (0.19)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.103->boto3->nemo_toolkit[all]) (1.26.18)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile->nemo_toolkit[all]) (2.22)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from cytoolz>=0.10.1->lhotse>=1.20.0->nemo_toolkit[all]) (0.12.1)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.10/site-packages (from Flask>=0.8->flask-restful->nemo_toolkit[all]) (2.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->nemo_toolkit[all]) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->nemo_toolkit[all]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->nemo_toolkit[all]) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->nemo_toolkit[all]) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->nemo_toolkit[all]) (4.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[all]) (4.0.11)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (3.0.42)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.0->sphinx->nemo_toolkit[all]) (2.1.5)\n",
      "Requirement already satisfied: typer>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[all]) (0.12.3)\n",
      "Requirement already satisfied: latexcodec>=1.0.4 in /opt/conda/lib/python3.10/site-packages (from pybtex>=0.24->sphinxcontrib-bibtex->nemo_toolkit[all]) (3.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers>=0.19.3->nemo_toolkit[all]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers>=0.19.3->nemo_toolkit[all]) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers>=0.19.3->nemo_toolkit[all]) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=12->nerfacc>=0.5.3->nemo_toolkit[all]) (3.0.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.1->pyannote.metrics->nemo_toolkit[all]) (1.3.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown->nemo_toolkit[all]) (2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers>=0.19.3->nemo_toolkit[all]) (3.17.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->nemo_toolkit[all]) (1.7.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[all]) (5.0.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (0.8.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12->nerfacc>=0.5.3->nemo_toolkit[all]) (0.1.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (0.7.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[all]) (1.5.4)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->nemo_toolkit[all]) (0.2.2)\n",
      "Using cached click-8.0.2-py3-none-any.whl (97 kB)\n",
      "Using cached jiwer-2.5.2-py3-none-any.whl (15 kB)\n",
      "Using cached rapidfuzz-2.13.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Installing collected packages: rapidfuzz, click, jiwer\n",
      "  Attempting uninstall: rapidfuzz\n",
      "    Found existing installation: rapidfuzz 3.9.0\n",
      "    Uninstalling rapidfuzz-3.9.0:\n",
      "      Successfully uninstalled rapidfuzz-3.9.0\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Successfully uninstalled click-8.1.7\n",
      "  Attempting uninstall: jiwer\n",
      "    Found existing installation: jiwer 3.0.4\n",
      "    Uninstalling jiwer-3.0.4:\n",
      "      Successfully uninstalled jiwer-3.0.4\n",
      "Successfully installed click-8.0.2 jiwer-2.5.2 rapidfuzz-2.13.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nemo_toolkit['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc2ac9ab-707e-4621-9a9b-5c2a5fce3103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-12 13:45:33 mixins:172] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-12 13:45:34 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-train-all.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 16.7\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2024-05-12 13:45:34 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-dev-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2024-05-12 13:45:34 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-12 13:45:34 features:289] PADDING: 0\n",
      "[NeMo I 2024-05-12 13:46:50 save_restore_connector:249] Model EncDecCTCModelBPE was successfully restored from /home/jupyter/.cache/huggingface/hub/models--nvidia--parakeet-ctc-0.6b/snapshots/097ffc5b027beabc73acb627def2d1d278e774e9/parakeet-ctc-0.6b.nemo.\n"
     ]
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "asr_model = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(model_name=\"nvidia/parakeet-ctc-0.6b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "655dc728-7e72-4514-a944-c92f8d368bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-14 13:32:06 nemo_logging:349] /opt/conda/lib/python3.10/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__name__',\n",
       " '__doc__',\n",
       " '__package__',\n",
       " '__loader__',\n",
       " '__spec__',\n",
       " '__path__',\n",
       " '__file__',\n",
       " '__cached__',\n",
       " '__builtins__',\n",
       " 'asr_model',\n",
       " 'configs',\n",
       " 'aed_multitask_models',\n",
       " 'EncDecMultiTaskModel',\n",
       " 'ASRModel',\n",
       " 'audio_to_audio_model',\n",
       " 'AudioToAudioModel',\n",
       " 'classification_models',\n",
       " 'EncDecClassificationModel',\n",
       " 'EncDecFrameClassificationModel',\n",
       " 'label_models',\n",
       " 'clustering_diarizer',\n",
       " 'ClusteringDiarizer',\n",
       " 'ctc_models',\n",
       " 'ctc_bpe_models',\n",
       " 'EncDecCTCModelBPE',\n",
       " 'EncDecCTCModel',\n",
       " 'enhancement_models',\n",
       " 'EncMaskDecAudioToAudioModel',\n",
       " 'rnnt_models',\n",
       " 'hybrid_rnnt_ctc_models',\n",
       " 'hybrid_rnnt_ctc_bpe_models',\n",
       " 'EncDecHybridRNNTCTCBPEModel',\n",
       " 'EncDecHybridRNNTCTCModel',\n",
       " 'rnnt_bpe_models',\n",
       " 'k2_sequence_models',\n",
       " 'EncDecK2RnntSeqModel',\n",
       " 'EncDecK2RnntSeqModelBPE',\n",
       " 'EncDecK2SeqModel',\n",
       " 'EncDecK2SeqModelBPE',\n",
       " 'EncDecSpeakerLabelModel',\n",
       " 'msdd_models',\n",
       " 'EncDecDiarLabelModel',\n",
       " 'NeuralDiarizer',\n",
       " 'EncDecRNNTBPEModel',\n",
       " 'EncDecRNNTModel',\n",
       " 'slu_models',\n",
       " 'SLUIntentSlotBPEModel',\n",
       " 'ssl_models',\n",
       " 'SpeechEncDecSelfSupervisedModel',\n",
       " 'transformer_bpe_models',\n",
       " 'EncDecTransfModelBPE']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "nemo_asr.models.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba238457-1b2a-42f5-b80e-1aa6772c022e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d87fa15-fef4-4035-b8fc-cffcfd4831bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dfe5b3500b424ebaec791de641bbde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29270926c31479398213286ffd27ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/805 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c221c799c848409ca89df2cf10fe6f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caaf6e0ead124d08a200d1bf401f2990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.41M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74637e93184a417bb860128f38057211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe9b9936d5049a6a031cf58c35e354d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858dc45309814835828d43a99c758193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4c89dace664916af370bc10dd4c8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/1.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336b7b3a-21dd-42a5-a49b-372902faed0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96118eac0aa34ed8bb239efc9622bfd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17354fdfe6eb46a5ba953a2396f19022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/290M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49885bbd09d14590b623d4062eb9add0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ab5b34-d9d8-4c3b-9c2b-31820e439921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paht = r\"novice/audio/audio_0.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e262268c-38fd-4fc4-b2a5-7edf6340586d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c65616f7-d119-4a24-90a6-24b0052332e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0a03c3d-33af-411e-b577-c546fd302ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(paht, 'rb') as f:\n",
    "    wav_file_bytesIO = BytesIO(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f25e6ac5-cf6c-4e0b-a9a4-049a478f9037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data, sr = torchaudio.load(wav_file_bytesIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2610fd9-1385-43cd-a69a-3a7e63071c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_features = processor(data[0], sampling_rate=sr, return_tensors=\"pt\").input_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d7fe75f-80b7-403f-8d4f-17c6f1030b58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predicted_ids = model.generate(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a695fc92-0334-4558-a376-0e9363da2711",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f367fe9-4ffe-4fbb-9d90-d63a6c00794a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Heading is 150 target is Green Commercial Aircraft tool to deploy electromagnetic pulse.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b6d0c38-78c9-4cb5-877d-49e5cc0abc97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.34.0\n",
      "  Downloading transformers-4.34.0-py3-none-any.whl.metadata (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (2024.5.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (2.31.0)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers==4.34.0)\n",
      "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0) (4.11.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.34.0)\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0) (2024.2.2)\n",
      "Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.23.0\n",
      "    Uninstalling huggingface-hub-0.23.0:\n",
      "      Successfully uninstalled huggingface-hub-0.23.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.31.0\n",
      "    Uninstalling transformers-4.31.0:\n",
      "      Successfully uninstalled transformers-4.31.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 2.19.1 requires huggingface-hub>=0.21.2, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "diffusers 0.27.2 requires huggingface-hub>=0.20.2, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.17.3 tokenizers-0.14.1 transformers-4.34.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.34.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6d4b1cb-ea65-4738-8540-c34a8946fed4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (0.17.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (3.14.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (2024.3.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (4.11.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (24.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f71500-1010-401a-8d57-c1af53af03d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyctcdecode\n",
      "  Using cached pyctcdecode-0.5.0-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from pyctcdecode) (1.26.4)\n",
      "Requirement already satisfied: pygtrie<3.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from pyctcdecode) (2.5.0)\n",
      "Requirement already satisfied: hypothesis<7,>=6.14 in /opt/conda/lib/python3.10/site-packages (from pyctcdecode) (6.102.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from hypothesis<7,>=6.14->pyctcdecode) (1.2.0)\n",
      "Using cached pyctcdecode-0.5.0-py2.py3-none-any.whl (39 kB)\n",
      "Installing collected packages: pyctcdecode\n",
      "Successfully installed pyctcdecode-0.5.0\n"
     ]
    }
   ],
   "source": [
    "#pip install https://github.com/kpu/kenlm/archive/master.zip\n",
    "!pip install pyctcdecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10913210-b924-40cb-bf6d-3f7a4d05dcaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bead53d40ca4a83a9292b0c1c099aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0bf3633930457fa6b05a1a7f5688b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8614fdcbb4934455b2bc69ccc1ab2a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/260 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3784c553b6d8464a9d1de79d135d4b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/284 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36cab7fe161541c7bd0915a22839d57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59c66719980432f9fcd4a1aee26785b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/30.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0e31e79d174142bb5b7d8267c59b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb15c15ae1d47a0943d34d004375815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 0 unigrams passed as vocabulary. Is this small or artificial data?\n"
     ]
    }
   ],
   "source": [
    "import torch, torchaudio\n",
    "from io import BytesIO\n",
    "from transformers import AutoModelForCTC, Wav2Vec2Processor, Wav2Vec2ProcessorWithLM\n",
    "import torchaudio.functional as F\n",
    "USE_LM = True\n",
    "\n",
    "MODEL_ID = \"Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim\"\n",
    "\n",
    "# 2. Load the model\n",
    "model = AutoModelForCTC.from_pretrained(MODEL_ID)\n",
    "\n",
    "# 3. Load the processors, we offer support with LM, which should yield better resutls\n",
    "if USE_LM:\n",
    "    processor = Wav2Vec2ProcessorWithLM.from_pretrained(MODEL_ID)\n",
    "else:\n",
    "    processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
    "# 4. Format the test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa9d425-def7-4fb4-91e5-9b32fb31e4b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-18 12:56:21.178841: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['heading is one five zero tor isrenomrtian ro uledint approa to make muitakponcee']\n"
     ]
    }
   ],
   "source": [
    "with open(r\"./novice/audio/audio_0.wav\", 'rb') as f:\n",
    "    wav_file_bytesIO = BytesIO(f.read())\n",
    "    data, sr = torchaudio.load(wav_file_bytesIO)\n",
    "input_features = processor(data[0], sampling_rate=sr, return_tensors=\"pt\").input_values\n",
    "\n",
    "# 5. Run the forward pass in the model\n",
    "with torch.no_grad():\n",
    "    logits = model(input_features).logits\n",
    "    \n",
    "# get the transcription with processor\n",
    "if USE_LM:\n",
    "    transcription = processor.batch_decode(logits.numpy()).text\n",
    "else:\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(pred_ids)\n",
    "#print the output\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd2a541-1e92-418f-86e9-d8234a109e87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
      "  Using cached https://github.com/kpu/kenlm/archive/master.zip\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install https://github.com/kpu/kenlm/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a1deb8d-bc01-45ce-a5cd-d7265c45e4a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "000d5d13-1685-46d4-90a1-5c6af6760b15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperFeatureExtractor\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")\n",
    "from transformers import WhisperTokenizer\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-tiny\", language=\"English\", task=\"transcribe\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7487beec-d3a8-4f0c-898e-55b4da8d0c05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperProcessor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\", language=\"English\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f561a2-ba05-40e5-bd9a-4ad21f06ab4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    from transformers import WhisperFeatureExtractor\n",
    "    feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")\n",
    "    from transformers import WhisperTokenizer\n",
    "    tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-tiny\", language=\"English\", task=\"transcribe\") \n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "    # encode target text to label ids \n",
    "    batch[\"labels\"] = tokenizer(batch[\"transcription\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120c04f8-e681-4e2c-9354-e29c22d370f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cabfe362-16f7-4bc3-bca8-5ae9aaf16ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"novice/asr.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f135dadd-a47a-488e-9887-968dfd46927c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"audio\"] = df[\"audio\"].apply(lambda x: rf\"novice/audio/{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "483a7a5d-73dc-4255-a904-859ac639e73c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>audio</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>novice/audio/audio_0.wav</td>\n",
       "      <td>Heading is one five zero, target is green comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>novice/audio/audio_1.wav</td>\n",
       "      <td>Heading is two six zero, target is black, whit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>novice/audio/audio_2.wav</td>\n",
       "      <td>Heading is one zero five, target is silver, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>novice/audio/audio_3.wav</td>\n",
       "      <td>Heading is two niner zero, target is brown and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>novice/audio/audio_4.wav</td>\n",
       "      <td>Heading is zero one five, target is yellow cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>3495</td>\n",
       "      <td>novice/audio/audio_3495.wav</td>\n",
       "      <td>Heading is zero niner five, target is blue hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>3496</td>\n",
       "      <td>novice/audio/audio_3496.wav</td>\n",
       "      <td>Heading is zero three zero, target is grey, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>3497</td>\n",
       "      <td>novice/audio/audio_3497.wav</td>\n",
       "      <td>Heading is two two five, target is green and g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>3498</td>\n",
       "      <td>novice/audio/audio_3498.wav</td>\n",
       "      <td>Heading is one eight five, target is red, brow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>3499</td>\n",
       "      <td>novice/audio/audio_3499.wav</td>\n",
       "      <td>Heading is zero four five, target is black and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       key                        audio  \\\n",
       "0        0     novice/audio/audio_0.wav   \n",
       "1        1     novice/audio/audio_1.wav   \n",
       "2        2     novice/audio/audio_2.wav   \n",
       "3        3     novice/audio/audio_3.wav   \n",
       "4        4     novice/audio/audio_4.wav   \n",
       "...    ...                          ...   \n",
       "3495  3495  novice/audio/audio_3495.wav   \n",
       "3496  3496  novice/audio/audio_3496.wav   \n",
       "3497  3497  novice/audio/audio_3497.wav   \n",
       "3498  3498  novice/audio/audio_3498.wav   \n",
       "3499  3499  novice/audio/audio_3499.wav   \n",
       "\n",
       "                                             transcript  \n",
       "0     Heading is one five zero, target is green comm...  \n",
       "1     Heading is two six zero, target is black, whit...  \n",
       "2     Heading is one zero five, target is silver, gr...  \n",
       "3     Heading is two niner zero, target is brown and...  \n",
       "4     Heading is zero one five, target is yellow cam...  \n",
       "...                                                 ...  \n",
       "3495  Heading is zero niner five, target is blue hel...  \n",
       "3496  Heading is zero three zero, target is grey, re...  \n",
       "3497  Heading is two two five, target is green and g...  \n",
       "3498  Heading is one eight five, target is red, brow...  \n",
       "3499  Heading is zero four five, target is black and...  \n",
       "\n",
       "[3500 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0efc965-1250-48f4-8021-af5402c3dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Audio\n",
    "\n",
    "ds = Dataset.from_dict({\n",
    "    \"audio\": df[\"audio\"].to_list(),\n",
    "    \"transcription\": df[\"transcript\"].to_list(),\n",
    "}).cast_column(\"audio\", Audio()).to_iterable_dataset(num_shards=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a37d518-eb27-45f2-9048-1654b9a77b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = ds.map(prepare_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b2959e8-3a15-4540-866b-dffe4fe20908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
    "model.generation_config.language = \"english\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "\n",
    "model.generation_config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f9a8066-d6aa-4c0e-99d9-aae8ceb4c77c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a12ec8ac-db8a-4e2a-a01b-f32429d285b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cca5f70e-3545-41ff-a825-74ff50b68876",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-18 13:59:42.813656: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc10602d-9d35-4a84-af74-3f245ca7d622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0309898b-fc6b-491e-ad81-5bab09dabeb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a044c9b-388c-46e2-a2a5-fdfe39afae6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-tiny-thing\",  # change to a repo name of your choice\n",
    "    dataloader_num_workers = 4,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=5000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    disable_tqdm=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06583f7c-c960-4bc1-a25e-6a4c01c8a776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=ds,\n",
    "    eval_dataset=ds,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "704d10c9-3fc9-4377-9c7a-ff207c9cd5f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aac665d4-0e0e-46c5-93b2-dfde42966687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1013' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1013/5000 1:14:42 < 4:54:36, 0.23 it/s, Epoch 4.03/9223372036854775807]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2165\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2162\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2164\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   2166\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/data_loader.py:710\u001b[0m, in \u001b[0;36mDataLoaderDispatcher.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m stop_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop_iteration\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stop_iteration:\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;66;03m# We may still be at the end of the dataloader without knowing it yet: if there is nothing left in\u001b[39;00m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;66;03m# the dataloader since the number of batches is a round multiple of the number of processes.\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     next_batch, next_batch_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;66;03m# next_batch_info[0] is None when there are no more batches, otherwise we still need to process them.\u001b[39;00m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop_iteration \u001b[38;5;129;01mand\u001b[39;00m next_batch_info[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/data_loader.py:631\u001b[0m, in \u001b[0;36mDataLoaderDispatcher._fetch_batches\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    629\u001b[0m batches \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mnum_processes):\n\u001b[0;32m--> 631\u001b[0m     batches\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    633\u001b[0m     batch \u001b[38;5;241m=\u001b[39m concatenate(batches, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1285\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1287\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6958db1-a639-47ab-8204-7582eeda7534",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/m-bain/whisperx.git\n",
      "  Cloning https://github.com/m-bain/whisperx.git to /var/tmp/pip-req-build-wzhh7dyu\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/m-bain/whisperx.git /var/tmp/pip-req-build-wzhh7dyu\n",
      "  Resolved https://github.com/m-bain/whisperx.git to commit f2da2f858e99e4211fe4f64b5f2938b007827e17\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch>=2 (from whisperx==3.1.1)\n",
      "  Using cached torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting torchaudio>=2 (from whisperx==3.1.1)\n",
      "  Using cached torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting faster-whisper==1.0.0 (from whisperx==3.1.1)\n",
      "  Using cached faster_whisper-1.0.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: transformers in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from whisperx==3.1.1) (4.40.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from whisperx==3.1.1) (2.2.2)\n",
      "Requirement already satisfied: setuptools>=65 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from whisperx==3.1.1) (69.5.1)\n",
      "Requirement already satisfied: nltk in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from whisperx==3.1.1) (3.8.1)\n",
      "Collecting pyannote.audio==3.1.1 (from whisperx==3.1.1)\n",
      "  Using cached pyannote.audio-3.1.1-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting av==11.* (from faster-whisper==1.0.0->whisperx==3.1.1)\n",
      "  Using cached av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting ctranslate2<5,>=4.0 (from faster-whisper==1.0.0->whisperx==3.1.1)\n",
      "  Using cached ctranslate2-4.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.13 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (0.23.0)\n",
      "Collecting tokenizers<0.16,>=0.13 (from faster-whisper==1.0.0->whisperx==3.1.1)\n",
      "  Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting onnxruntime<2,>=1.14 (from faster-whisper==1.0.0->whisperx==3.1.1)\n",
      "  Using cached onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting asteroid-filterbanks>=0.4 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting einops>=0.6.0 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting lightning>=2.0.1 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached lightning-2.2.4-py3-none-any.whl.metadata (53 kB)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (2.3.0)\n",
      "Requirement already satisfied: pyannote.core>=5.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (5.0.0)\n",
      "Requirement already satisfied: pyannote.database>=5.0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (5.1.0)\n",
      "Requirement already satisfied: pyannote.metrics>=3.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (3.2.1)\n",
      "Collecting pyannote.pipeline>=3.0.1 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
      "Collecting pytorch-metric-learning>=2.1.0 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached pytorch_metric_learning-2.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: rich>=12.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (13.7.1)\n",
      "Collecting semver>=3.0.0 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (0.12.1)\n",
      "Collecting speechbrain>=0.5.14 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached speechbrain-1.0.0-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: tensorboardX>=2.6 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (2.6.2.2)\n",
      "Collecting torch-audiomentations>=0.11.0 (from pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached torch_audiomentations-0.11.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (1.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=2->whisperx==3.1.1) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=2->whisperx==3.1.1) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=2->whisperx==3.1.1) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=2->whisperx==3.1.1) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=2->whisperx==3.1.1) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=2->whisperx==3.1.1) (2024.3.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->whisperx==3.1.1)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->whisperx==3.1.1)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->whisperx==3.1.1)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->whisperx==3.1.1)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->whisperx==3.1.1)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->whisperx==3.1.1)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->whisperx==3.1.1)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->whisperx==3.1.1)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->whisperx==3.1.1)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2->whisperx==3.1.1)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->whisperx==3.1.1)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch>=2->whisperx==3.1.1) (2.3.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->whisperx==3.1.1)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: click in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nltk->whisperx==3.1.1) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nltk->whisperx==3.1.1) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nltk->whisperx==3.1.1) (2024.5.10)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nltk->whisperx==3.1.1) (4.66.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->whisperx==3.1.1) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->whisperx==3.1.1) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->whisperx==3.1.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas->whisperx==3.1.1) (2024.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers->whisperx==3.1.1) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers->whisperx==3.1.1) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers->whisperx==3.1.1) (2.31.0)\n",
      "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting transformers (from whisperx==3.1.1)\n",
      "  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from transformers->whisperx==3.1.1) (0.4.3)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (0.11.2)\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.0.7)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from omegaconf<3.0,>=2.1->pyannote.audio==3.1.1->whisperx==3.1.1) (4.9.3)\n",
      "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: protobuf in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1) (3.20.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.core>=5.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.core>=5.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.11.4)\n",
      "Requirement already satisfied: typer>=0.12.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (0.12.3)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (1.4.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.6.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (3.8.4)\n",
      "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->whisperx==3.1.1) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (2.17.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.16.0)\n",
      "Collecting hyperpyyaml (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (0.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from sympy->torch>=2->whisperx==3.1.1) (1.3.0)\n",
      "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached julius-0.2.7-py3-none-any.whl\n",
      "Requirement already satisfied: librosa>=0.6.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.10.2)\n",
      "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached torch_pitch_shift-1.2.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pretty-errors==1.2.25 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torchmetrics>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.2.25)\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pretty-errors==1.2.25->torchmetrics>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jinja2->torch>=2->whisperx==3.1.1) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers->whisperx==3.1.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers->whisperx==3.1.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers->whisperx==3.1.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->transformers->whisperx==3.1.1) (2024.2.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.22)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (3.9.5)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.59.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.8.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.3.7)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.0.8)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (3.1.2)\n",
      "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.0.29)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (3.5.0)\n",
      "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.5.4)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (0.18.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (4.0.3)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1)\n",
      "  Using cached Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (4.2.1)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (0.2.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.3)\n",
      "Using cached faster_whisper-1.0.0-py3-none-any.whl (1.5 MB)\n",
      "Using cached pyannote.audio-3.1.1-py2.py3-none-any.whl (208 kB)\n",
      "Using cached av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n",
      "Using cached torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Using cached torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
      "Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hUsing cached asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
      "Using cached ctranslate2-4.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (179.4 MB)\n",
      "Using cached einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Using cached lightning-2.2.4-py3-none-any.whl (2.0 MB)\n",
      "Using cached onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "Using cached pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
      "Using cached pytorch_metric_learning-2.5.0-py3-none-any.whl (119 kB)\n",
      "Using cached semver-3.0.2-py3-none-any.whl (17 kB)\n",
      "Using cached speechbrain-1.0.0-py3-none-any.whl (760 kB)\n",
      "Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Using cached torch_audiomentations-0.11.1-py3-none-any.whl (50 kB)\n",
      "Using cached optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "Using cached torch_pitch_shift-1.2.4-py3-none-any.whl (4.9 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached primePy-1.3-py3-none-any.whl (4.0 kB)\n",
      "Using cached colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Using cached Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: whisperx\n",
      "  Building wheel for whisperx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for whisperx: filename=whisperx-3.1.1-py3-none-any.whl size=38605 sha256=1ac41d5fe73040ca0cd60a1b4d0f24fc858c0c426ad8a25ab250db381fad15ce\n",
      "  Stored in directory: /var/tmp/pip-ephem-wheel-cache-rkh0s_tz/wheels/27/fb/53/682b85073a466f1866910d7257233e53b0cc126ab50e7c5373\n",
      "Successfully built whisperx\n",
      "Installing collected packages: primePy, flatbuffers, semver, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, humanfriendly, einops, ctranslate2, colorlog, av, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hyperpyyaml, coloredlogs, alembic, tokenizers, optuna, onnxruntime, nvidia-cusolver-cu12, transformers, torch, faster-whisper, torchaudio, pytorch-metric-learning, pyannote.pipeline, julius, asteroid-filterbanks, torch-pitch-shift, speechbrain, torch-audiomentations, lightning, pyannote.audio, whisperx\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.40.2\n",
      "    Uninstalling transformers-4.40.2:\n",
      "      Successfully uninstalled transformers-4.40.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/envs/pytorch/lib/python3.10/site-packages/~orch'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.14.1 requires torch==1.13.1, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.5 alembic-1.13.1 asteroid-filterbanks-0.4.0 av-11.0.0 coloredlogs-15.0.1 colorlog-6.8.2 ctranslate2-4.2.1 einops-0.8.0 faster-whisper-1.0.0 flatbuffers-24.3.25 humanfriendly-10.0 hyperpyyaml-1.2.2 julius-0.2.7 lightning-2.2.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 onnxruntime-1.17.3 optuna-3.6.1 primePy-1.3 pyannote.audio-3.1.1 pyannote.pipeline-3.0.1 pytorch-metric-learning-2.5.0 semver-3.0.2 speechbrain-1.0.0 tokenizers-0.15.2 torch-2.3.0 torch-audiomentations-0.11.1 torch-pitch-shift-1.2.4 torchaudio-2.3.0 transformers-4.39.3 whisperx-3.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/m-bain/whisperx.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73d3a545-6af3-4451-bb57-8b4540dc6741",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "2024-05-17 14:14:58.063750: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.10/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    }
   ],
   "source": [
    "import whisperx\n",
    "import gc \n",
    "\n",
    "device = \"cuda\" \n",
    "audio_file = \"novice/audio/audio_0.wav \"\n",
    "batch_size = 16 # reduce if low on GPU mem\n",
    "compute_type = \"float16\" # change to \"int8\" if low on GPU mem (may reduce accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f605aa-fdc9-4cec-8397-720e6c6e802d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file .cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN version incompatibility: PyTorch was compiled  against (8, 9, 2) but found runtime version (8, 5, 0). PyTorch already comes bundled with cuDNN. One option to resolving this error is to ensure PyTorch can find the bundled cuDNN. Looks like your LD_LIBRARY_PATH contains incompatible version of cudnn. Please either remove it from the path or install cudnn (8, 9, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Transcribe with original whisper (batched)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mwhisperx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlarge-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# save model to local path (optional)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# model_dir = \"/path/\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type, download_root=model_dir)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/whisperx/asr.py:347\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(whisper_arch, device, device_index, compute_type, asr_options, language, vad_model, vad_options, model, task, download_root, threads)\u001b[0m\n\u001b[1;32m    345\u001b[0m     vad_model \u001b[38;5;241m=\u001b[39m vad_model\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     vad_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_vad_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdefault_vad_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m FasterWhisperPipeline(\n\u001b[1;32m    350\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    351\u001b[0m     vad\u001b[38;5;241m=\u001b[39mvad_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    356\u001b[0m     vad_params\u001b[38;5;241m=\u001b[39mdefault_vad_options,\n\u001b[1;32m    357\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/whisperx/vad.py:56\u001b[0m, in \u001b[0;36mload_vad_model\u001b[0;34m(device, vad_onset, vad_offset, use_auth_token, model_fp)\u001b[0m\n\u001b[1;32m     51\u001b[0m vad_model \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_fp, use_auth_token\u001b[38;5;241m=\u001b[39muse_auth_token)\n\u001b[1;32m     52\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monset\u001b[39m\u001b[38;5;124m\"\u001b[39m: vad_onset, \n\u001b[1;32m     53\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffset\u001b[39m\u001b[38;5;124m\"\u001b[39m: vad_offset,\n\u001b[1;32m     54\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_duration_on\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m     55\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_duration_off\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.1\u001b[39m}\n\u001b[0;32m---> 56\u001b[0m vad_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mVoiceActivitySegmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvad_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m vad_pipeline\u001b[38;5;241m.\u001b[39minstantiate(hyperparameters)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vad_pipeline\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/whisperx/vad.py:207\u001b[0m, in \u001b[0;36mVoiceActivitySegmentation.__init__\u001b[0;34m(self, segmentation, fscore, use_auth_token, **inference_kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    201\u001b[0m     segmentation: PipelineModel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyannote/segmentation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minference_kwargs,\n\u001b[1;32m    205\u001b[0m ):\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msegmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msegmentation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minference_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyannote/audio/pipelines/voice_activity_detection.py:128\u001b[0m, in \u001b[0;36mVoiceActivityDetection.__init__\u001b[0;34m(self, segmentation, fscore, use_auth_token, **inference_kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(segmentation, use_auth_token\u001b[38;5;241m=\u001b[39muse_auth_token)\n\u001b[1;32m    125\u001b[0m inference_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_aggregation_hook\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m scores: np\u001b[38;5;241m.\u001b[39mmax(\n\u001b[1;32m    126\u001b[0m     scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    127\u001b[0m )\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_segmentation \u001b[38;5;241m=\u001b[39m \u001b[43mInference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minference_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mspecifications\u001b[38;5;241m.\u001b[39mpowerset:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyannote/audio/core/inference.py:116\u001b[0m, in \u001b[0;36mInference.__init__\u001b[0;34m(self, model, window, duration, step, pre_aggregation_hook, skip_aggregation, skip_conversion, device, batch_size, use_auth_token)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m specifications \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mspecifications\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# ~~~~ sliding window ~~~~~\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightning_fabric/utilities/device_dtype_mixin.py:54\u001b[0m, in \u001b[0;36m_DeviceDtypeModuleMixin.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m device, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_parse_to(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__update_properties(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:222\u001b[0m, in \u001b[0;36mRNNBase._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    217\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_apply(fn, recurse)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Resets _flat_weights\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# Note: be v. careful before removing this, as 3rd party device types\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# likely rely on this behavior to properly .to() modules like LSTM.\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_flat_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:158\u001b[0m, in \u001b[0;36mRNNBase._init_flat_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m wn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names]\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weight_refs \u001b[38;5;241m=\u001b[39m [weakref\u001b[38;5;241m.\u001b[39mref(w) \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    157\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights]\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:188\u001b[0m, in \u001b[0;36mRNNBase.flatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m dtype \u001b[38;5;241m=\u001b[39m first_fw\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fw \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fw\u001b[38;5;241m.\u001b[39mdata, Tensor) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (fw\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtype) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m fw\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mis_cuda \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_acceptable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# If any parameters alias, we fall back to the slower, copying code path. This is\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# a sufficient check, because overlapping parameter buffers that don't completely\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# alias would break the assumptions of the uniqueness check in\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Module.named_parameters().\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/backends/cudnn/__init__.py:111\u001b[0m, in \u001b[0;36mis_acceptable\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    106\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch was compiled without cuDNN/MIOpen support. To use cuDNN/MIOpen, rebuild \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch making sure the library is visible to the build system.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m     )\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    112\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuDNN/MIOpen library not found. Check your \u001b[39m\u001b[38;5;132;01m{libpath}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    114\u001b[0m             libpath\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdarwin\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDYLD_LIBRARY_PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;124m\"\u001b[39m}\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m         )\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/backends/cudnn/__init__.py:59\u001b[0m, in \u001b[0;36m_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m ld_library_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLD_LIBRARY_PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m     57\u001b[0m     substring \u001b[38;5;129;01min\u001b[39;00m ld_library_path \u001b[38;5;28;01mfor\u001b[39;00m substring \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcudnn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     58\u001b[0m ):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_error_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLooks like your LD_LIBRARY_PATH contains incompatible version of cudnn. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease either remove it from the path or install cudnn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompile_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m     )\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_error_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone possibility is that there is a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconflicting cuDNN in LD_LIBRARY_PATH.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN version incompatibility: PyTorch was compiled  against (8, 9, 2) but found runtime version (8, 5, 0). PyTorch already comes bundled with cuDNN. One option to resolving this error is to ensure PyTorch can find the bundled cuDNN. Looks like your LD_LIBRARY_PATH contains incompatible version of cudnn. Please either remove it from the path or install cudnn (8, 9, 2)"
     ]
    }
   ],
   "source": [
    "# 1. Transcribe with original whisper (batched)\n",
    "model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type)\n",
    "\n",
    "# save model to local path (optional)\n",
    "# model_dir = \"/path/\"\n",
    "# model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type, download_root=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d95e2a-151e-4ccb-b122-a41447942402",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ffmpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[43mwhisperx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtranscribe(audio, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegments\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;66;03m# before alignment\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/whisperx/audio.py:61\u001b[0m, in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Launches a subprocess to decode audio while down-mixing and resampling as necessary.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# Requires the ffmpeg CLI to be installed.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mffmpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-nostdin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     60\u001b[0m     ]\n\u001b[0;32m---> 61\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    501\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/subprocess.py:1863\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1862\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffmpeg'"
     ]
    }
   ],
   "source": [
    "audio = whisperx.load_audio(audio_file)\n",
    "result = model.transcribe(audio, batch_size=batch_size)\n",
    "print(result[\"segments\"]) # before alignment\n",
    "\n",
    "# # delete model if low on GPU resources\n",
    "# # import gc; gc.collect(); torch.cuda.empty_cache(); del model\n",
    "\n",
    "# # 2. Align whisper output\n",
    "# model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
    "# result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
    "\n",
    "# print(result[\"segments\"]) # after alignment\n",
    "\n",
    "# # delete model if low on GPU resources\n",
    "# # import gc; gc.collect(); torch.cuda.empty_cache(); del model_a\n",
    "\n",
    "# # 3. Assign speaker labels\n",
    "# diarize_model = whisperx.DiarizationPipeline(use_auth_token=YOUR_HF_TOKEN, device=device)\n",
    "\n",
    "# # add min/max number of speakers if known\n",
    "# diarize_segments = diarize_model(audio)\n",
    "# # diarize_model(audio, min_speakers=min_speakers, max_speakers=max_speakers)\n",
    "\n",
    "# result = whisperx.assign_word_speakers(diarize_segments, result)\n",
    "# print(diarize_segments)\n",
    "# print(result[\"segments\"]) # segments are now assigned speaker IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed4629e-c5d1-4adb-8754-e452467efa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 15:20:57.097168: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers.utils import is_flash_attn_2_available\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-large-v3\", # select checkpoint from https://huggingface.co/openai/whisper-large-v3#model-details\n",
    "    torch_dtype=torch.float16,\n",
    "    device=\"cuda:0\", # or mps for Mac devices\n",
    "    model_kwargs={\"attn_implementation\": \"flash_attention_2\"} if is_flash_attn_2_available() else {\"attn_implementation\": \"sdpa\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20672557-35df-4aef-a3c2-dbed5e71f246",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(\n",
    "    \"novice/audio/audio_2733.wav\",\n",
    "    chunk_length_s=30,\n",
    "    batch_size=24,\n",
    "    return_timestamps=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d63fea49-0741-4bea-9a68-8375c0c1e8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Heading is 045. Target is blue and orange camouflage drone. Tool to deploy is anti-air artillery.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6f7f6d-9d18-42e6-ad66-347e1e0125a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tf-keras) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf-keras) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8524c799-3532-40de-9a2a-0afd596b4c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffmpeg\n",
      "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: ffmpeg\n",
      "  Building wheel for ffmpeg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=d566683d5f7b49e2a23d91fb34d65c98a7581a10e7bb2959cf6de3e189a0c524\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
      "Successfully built ffmpeg\n",
      "Installing collected packages: ffmpeg\n",
      "Successfully installed ffmpeg-1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a4a10c-608a-4718-addc-52010b01160b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.34.0)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
      "Collecting optimum\n",
      "  Downloading optimum-1.19.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.30.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.14.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Using cached huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from optimum) (15.0.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum) (1.12)\n",
      "Requirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.10/site-packages (from optimum) (2.3.0+cu121)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum) (2.19.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11->optimum) (12.4.127)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.41.0,>=4.26.0->optimum) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.41.0,>=4.26.0->optimum) (3.20.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->optimum) (10.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n",
      "Using cached transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "Downloading optimum-1.19.2-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.0/417.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Installing collected packages: huggingface-hub, tokenizers, transformers, optimum\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.17.3\n",
      "    Uninstalling huggingface-hub-0.17.3:\n",
      "      Successfully uninstalled huggingface-hub-0.17.3\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.14.1\n",
      "    Uninstalling tokenizers-0.14.1:\n",
      "      Successfully uninstalled tokenizers-0.14.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.34.0\n",
      "    Uninstalling transformers-4.34.0:\n",
      "      Successfully uninstalled transformers-4.34.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "faster-whisper 1.0.0 requires tokenizers<0.16,>=0.13, but you have tokenizers 0.19.1 which is incompatible.\n",
      "spacy-transformers 1.3.5 requires transformers<4.37.0,>=3.4.0, but you have transformers 4.40.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.23.0 optimum-1.19.2 tokenizers-0.19.1 transformers-4.40.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers optimum accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bd691d3-cbbd-4e66-85d8-04f3359350b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import_m = WhisperForConditionalGeneration.from_pretrained(\"whisper-tiny-thing/checkpoint-1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc4c92c9-5131-4b41-be57-54d4bd5179c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\", language=\"English\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ac3038e-ba1a-4e4f-97b8-f751cc7e33a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-tiny\", language=\"English\", task=\"transcribe\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30093df5-d24c-400b-8ed4-4ccdcb68b6d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 13:33:03.611667: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a63c1284-1dd3-4744-984d-87bf24720294",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3c9ff32-dee7-41d0-a5ee-31618a86e710",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "\"automatic-speech-recognition\",\n",
    "model=\"./asr_models/my_whisper/asr/src/checkpoint-1000\",\n",
    "tokenizer=tokenizer,\n",
    "chunk_length_s=30,\n",
    "device=\"cuda:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec2d0aeb-5e5a-4a48-87d7-4249b308f0d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compiled_pipe = torch.compile(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dc558b5-34a9-4131-8d69-1e2c6bb65315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78ace5fd-69b9-400c-9fb8-8e58fa61f634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"novice/audio/audio_2733.wav\", \"rb\") as f:\n",
    "    data = BytesIO(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90ea4e70-92e7-4bd7-9277-a2eb52049dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70c4d4ca-8c5d-4fcb-942d-e8feadee8d02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data, sr = torchaudio.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74fb2cf4-b383-49bb-ad88-cacce83026ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.010417938232422"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "tik = time.time()\n",
    "text = pipe(data[0].numpy())[\"text\"]\n",
    "tok = time.time()\n",
    "tok-tik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdd1c7d1-5955-435f-a911-a8df7cf188e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-05-20 13:35:19 nemo_logging:349] /opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py:1778: UserWarning: Torchinductor does not support code generation for complex operators. Performance may be worse than eager.\n",
      "      warnings.warn(\n",
      "    \n",
      "[NeMo W 2024-05-20 13:35:22 nemo_logging:349] /opt/conda/lib/python3.10/site-packages/torch/_dynamo/utils.py:1764: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "      return node.target(*args, **kwargs)\n",
      "    \n",
      "[NeMo W 2024-05-20 13:35:22 nemo_logging:349] /opt/conda/lib/python3.10/site-packages/torch/fx/interpreter.py:274: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "      return target(*args, **kwargs)\n",
      "    \n",
      "[NeMo W 2024-05-20 13:35:22 nemo_logging:349] /opt/conda/lib/python3.10/site-packages/torch/fx/interpreter.py:274: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "      return target(*args, **kwargs)\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/tmp/ipykernel_8891/1600375898.py\", line 3, in <module>\n",
      "    text = compiled_pipe(data[0].numpy())[\"text\"]\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\", line 451, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_dynamo/external_utils.py\", line 36, in inner\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 285, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1236, in __call__\n",
      "    self.get_iterator(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1234, in torch_dynamo_resume_in___call___at_1236\n",
      "    return next(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n",
      "    item = next(self.iterator)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py\", line 269, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1141, in forward\n",
      "    with self.device_placement():\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1149, in torch_dynamo_resume_in_forward_at_1141\n",
      "    model_outputs = self._forward(model_inputs, **forward_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 496, in _forward\n",
      "    tokens = self.model.generate(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py\", line 382, in generate\n",
      "    The duration of output token in seconds. *E.g.* 0.02 means that a generated token on average accounts\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1269, in _prepare_generation_config\n",
      "    generate_attributes_in_kwargs = [\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1273, in torch_dynamo_resume_in__prepare_generation_config_at_1269\n",
      "    raise ValueError(\n",
      "ValueError: `torch.compile` exception: all generation configuration attributes must be passed within a `generation_config` instance passed to `generate` (found: ['encoder_outputs']).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1448, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1339, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1186, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1076, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 77, in collapse_repeated\n",
      "    for is_highlighted, group in itertools.groupby(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 45, in highlight_unique\n",
      "    counts = Counter(lst)\n",
      "  File \"/opt/conda/lib/python3.10/collections/__init__.py\", line 577, in __init__\n",
      "    self.update(iterable, **kwds)\n",
      "  File \"/opt/conda/lib/python3.10/collections/__init__.py\", line 670, in update\n",
      "    _count_elements(self, iterable)\n",
      "TypeError: unhashable type: 'dict'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tik = time.time()\n",
    "text = compiled_pipe(data[0].numpy())[\"text\"]\n",
    "tok = time.time()\n",
    "tok-tik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab88ebe1-6097-407d-a286-2742c7925612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Heading is zero four five, target is blue and orange camouflage drone, tool to deploy is anti-air artillery.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072dbfab-d6d7-4394-9a2b-a96fef839a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_pred(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    input_features = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "    batch[\"reference\"] = processor.tokenizer._normalize(batch['text'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features.to(\"cuda\"))[0]\n",
    "    transcription = processor.decode(predicted_ids)\n",
    "    batch[\"prediction\"] = processor.tokenizer._normalize(transcription)\n",
    "    return batch"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
